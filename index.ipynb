{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      1448\n",
      "           1       0.85      0.97      0.91       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.92      0.97      0.95      1672\n",
      "weighted avg       0.98      0.97      0.97      1672\n",
      "\n",
      "ROC AUC for MultinomialNB: 0.9893\n",
      "Precision-Recall AUC for MultinomialNB: 0.9755\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1448\n",
      "           1       1.00      0.92      0.95       224\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.96      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n",
      "ROC AUC for RandomForestClassifier: 0.9962\n",
      "Precision-Recall AUC for RandomForestClassifier: 0.9881\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1448\n",
      "           1       0.92      0.96      0.94       224\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.96      0.97      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n",
      "ROC AUC for LogisticRegression: 0.9904\n",
      "Precision-Recall AUC for LogisticRegression: 0.9753\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report for XGBClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1448\n",
      "           1       0.97      0.89      0.93       224\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.97      0.94      0.96      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n",
      "ROC AUC for XGBClassifier: 0.9851\n",
      "Precision-Recall AUC for XGBClassifier: 0.9688\n",
      "--------------------------------------------------------------------------------\n",
      "RandomForestClassifier(class_weight='balanced', random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "# Encode labels: 'ham' = 0, 'spam' = 1\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  \n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to resample the training data (balance the dataset)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Dictionary of models to evaluate\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(scale_pos_weight=1, random_state=42)\n",
    "}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Get probabilities for class 1 (spam)\n",
    "\n",
    "    # Print classification report\n",
    "    print(f\"Classification Report for {model.__class__.__name__}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Calculate ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    print(f'ROC AUC for {model.__class__.__name__}: {roc_auc:.4f}')\n",
    "    \n",
    "    # Calculate Precision-Recall AUC\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    print(f'Precision-Recall AUC for {model.__class__.__name__}: {pr_auc:.4f}')\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    return model\n",
    "\n",
    "# Loop through all models and evaluate\n",
    "best_model = None\n",
    "for model_name, model in models.items():\n",
    "    trained_model = evaluate_model(model, X_train_resampled, y_train_resampled, X_test, y_test)\n",
    "    \n",
    "    # If this model gives the best accuracy, update `best_model`\n",
    "    if not best_model or classification_report(y_test, trained_model.predict(X_test)).split()[-2] > classification_report(y_test, best_model.predict(X_test)).split()[-2]:\n",
    "        best_model = trained_model\n",
    "\n",
    "\n",
    "print(best_model)\n",
    "# Now save the best model, vectorizer, and label encoder\n",
    "joblib.dump(best_model, 'spam_classifier_model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
